import tensorflow.compat.v1 as tf
import numpy as np

tf.disable_v2_behavior()

ğ’· = tf.Variable([.3], tf.float32)
ğ“Œ = tf.Variable([-.3], tf.float32)

x =  tf.placeholder(tf.float32)
y =  tf.placeholder(tf.float32)

x_data = [79.5389363074,79.5381323935,79.527194372,79.527194372,79.5389363074,79.5389363074]
y_data = [3.73,2.93,4.42,1.51,7.66,4.34]

learning_rate = 0.003
model = (ğ“Œ * ğ“Œ * x) + ğ’·
delta = tf.square(model - y)
loss = tf.reduce_sum(delta)
optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)

    for i in range(10000):
        feed_dict_batch = {x: x_data, y: y_data}
        sess.run(optimizer, feed_dict = feed_dict_batch)

    approx_w, approx_b = sess.run([ğ“Œ, ğ’·])
    print("ğ“Œ â‰ˆ", approx_w, "and ğ’· â‰ˆ", approx_b)